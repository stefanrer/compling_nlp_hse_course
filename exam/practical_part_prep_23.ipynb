{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ce6aa68",
   "metadata": {},
   "source": [
    "# Задание 1.\n",
    "\n",
    "Разбейте текст ниже на предложения с помощью библиотеки razdel. Токенизируйте 4-е (в коде это индекс 3, так как в питоне считется с 0) предложение с помощью word_tokenizer из nltk.\n",
    "Разберите каждый отдельный токен этого предложения через pymorphy. Для каждого слова выберите последний по вероятности доступный разбор (если разбор только один, то выберите его) и выделите только части речи. Совместите частеречные теги этого предложения в одну строку (разделитель - пробел). Итоговую строку вставьте в форму для экзамена.\n",
    "\n",
    "*Если в разборе есть теги None, то не убирайте их, а просто превратите в строки 'None'. При копировании результата ковычки лучше не включать, но это не влияет на корректность ответа (сработает и так и так, если сама последовательность правильная)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from razdel import sentenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pymorphy2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T04:57:33.075974600Z",
     "start_time": "2023-06-23T04:57:32.264630400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54488642",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Diablo — одна из самых известных видеоигровых серий. Каждую новую часть ждут с нетерпением\n",
    "Первая Diablo изменила индустрию видеоигр — пусть и не создала новый жанр, но стала в нем главным ориентиром. Эта игра вышла в 1997 году. Тогда в портфолио студии-разработчика Blizzard Entertainment уже была стратегия WarCraft и несколько игр для консоли Sega Genesis.\n",
    "\n",
    "RPG тех лет были сложными для освоения. Во-первых, управлять чаще всего нужно было группой из нескольких персонажей — каждый со своими характеристиками и способностями. Во-вторых, чтобы узнать обо всех возможностях игры, нередко приходилось изучать руководства и инструкции.\n",
    "\n",
    "Diablo пыталась сделать жанр ролевых игр доступным для широкой аудитории. Под контролем оказывался не отряд приключенцев, а один герой. Вместо десятка характеристик и навыков — четыре параметра: сила, ловкость, живучесть и энергия, которая отвечает за магические способности. Эти атрибуты и нужно было улучшать. А еще — открывать новые заклинания и способности с помощью книг, которые выпадали из поверженных врагов.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccbb1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [sentence.text for sentence in sentenize(text)]\n",
    "tokens = word_tokenize(sentences[3])\n",
    "pos_tags = []\n",
    "for token in tokens:\n",
    "    parsed_token = morph.parse(token)\n",
    "    pos_tags.append(parsed_token[-1].tag.POS or 'None')\n",
    "result = ' '.join(pos_tags)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede26498",
   "metadata": {},
   "source": [
    "## Задание 2.\n",
    "\n",
    "Вам даны две последовательности с правильными ответами для бинарной классификации и для многоклассовой классификации. А также функция, которая генерирует случайные предсказание заданной длины и с заданным количеством классов. \n",
    "\n",
    "а) Сгенерируйте 5 тысяч случайных предсказаний для бинарной классификации и сравните каждое случайное предсказание с правильными ответами для бинарной классификации. Расчитайте точность (precision) каждого предсказания и рассчитайте усредненную точность на всех предсказаниях. Округлите полученную точность до 2 знака после запятой и вставьте в форму для экзамена в соответствующее поле.\n",
    "\n",
    "б) Сгенерируйте 5 тысяч случайных предсказаний для многлассовой классификации и сравните каждое случайное предсказание с правильными ответами для многоклассовой классификации. Расчитайте полноту (recall) каждого предсказания (используя макроусреднение по классам) и рассчитайте усредненную полноту на всех предсказаниях. Округлите полученную полноту до 2 знака после запятой и вставьте в форму для экзамена в соответствующее поле.\n",
    "\n",
    "\n",
    "*при вызове функции для генерации предсказаний укажите нужное количество классов (2 или 5) и нужную длину последовательности (10 для бинарной, 15 для многоклассовой)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T05:01:01.248890200Z",
     "start_time": "2023-06-23T05:01:01.239883200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef070800",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T05:01:05.495273300Z",
     "start_time": "2023-06-23T05:01:05.484250600Z"
    }
   },
   "outputs": [],
   "source": [
    "binary_true = [1,1,1,1,0,1,0,1,0,1]\n",
    "multiclass_true = [1,2,0,0,3,4,0,1,2,2,4,0,0,1,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02ec5958",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T05:01:10.826457200Z",
     "start_time": "2023-06-23T05:01:10.812650200Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# можно использовать другие библиотеки, например sklearn\n",
    "\n",
    "def predict_random(n_classes: int, length: int):\n",
    "    preds = []\n",
    "    for i in range(length):\n",
    "        preds.append(np.random.randint(0,n_classes))\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robst\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\robst\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\robst\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\robst\\anaconda3\\envs\\test\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "binary_precision_scores = []\n",
    "for i in range(5000):\n",
    "    binary_pred = predict_random(2, 10)\n",
    "    binary_precision_scores.append(precision_score(binary_true,binary_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T05:03:13.475924700Z",
     "start_time": "2023-06-23T05:03:10.744276Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision for binary classification: 0.7\n"
     ]
    }
   ],
   "source": [
    "binary_avg_precision = round(sum(binary_precision_scores)/len(binary_precision_scores), 2)\n",
    "print(f\"Average precision for binary classification: {binary_avg_precision}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T05:03:13.521874800Z",
     "start_time": "2023-06-23T05:03:13.477934900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "multiclass_recall_scores = []\n",
    "for i in range(5000):\n",
    "    multiclass_pred = predict_random(5, 15)\n",
    "    multiclass_recall_scores.append(recall_score(multiclass_true,multiclass_pred, average='macro'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T05:03:16.126282400Z",
     "start_time": "2023-06-23T05:03:13.492875300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average recall for multiclass classification: 0.2\n"
     ]
    }
   ],
   "source": [
    "multiclass_avg_recall = round(sum(multiclass_recall_scores)/len(multiclass_recall_scores), 2)\n",
    "print(f\"Average recall for multiclass classification: {multiclass_avg_recall}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T05:03:16.131276400Z",
     "start_time": "2023-06-23T05:03:16.120276300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "3dd46798",
   "metadata": {},
   "source": [
    "## Задание 3\n",
    "\n",
    "Загрузите токенизатор и модель 'distilbert-base-uncased'. Токенизируйте и рассчитайте векторные представления для двух приведенных ниже текстов. Усредните векторные представления токенов каждого из текстов так, чтобы для каждого из текстов получился вектор размером 768. \n",
    "Рассчитайте косинусное расстояние между двумя этим векторами, округлите его до 2 знака после запятой и вставьте число в форму."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "739b6f82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T05:09:49.053961200Z",
     "start_time": "2023-06-23T05:09:47.644435500Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0fd81883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "098b59e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T05:13:21.782277100Z",
     "start_time": "2023-06-23T05:13:21.776207700Z"
    }
   },
   "outputs": [],
   "source": [
    "text1 = \"Diablo — одна из самых известных видеоигровых серий.\"\n",
    "text2 = \"Diablo пыталась сделать жанр ролевых игр доступным для широкой аудитории.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cbe39462",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T05:10:21.853637600Z",
     "start_time": "2023-06-23T05:10:03.546817300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading (…)solve/main/vocab.txt: 0.00B [00:00, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ece0523e5a17472287fbda9a61c37a96"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robst\\anaconda3\\envs\\test\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\robst\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0da278f2745445c99131386ddf52fba9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5289a759432f4cfbac2995317f1b5e67"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "36b1ad6ef08643e6aa1323cb792b2c15"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59b423b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T05:13:25.025538300Z",
     "start_time": "2023-06-23T05:13:25.004531100Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_text_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    text_embedding = torch.mean(last_hidden_states[0], dim=0)\n",
    "    return text_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "text1_embedding = get_text_embedding(text1)\n",
    "text2_embedding = get_text_embedding(text2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T05:13:26.825223900Z",
     "start_time": "2023-06-23T05:13:25.449334900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine distance between the two texts: 0.02\n",
      "<class 'numpy.float32'>\n"
     ]
    }
   ],
   "source": [
    "cosine_distance = cosine_distances(text1_embedding.reshape(1,-1), text2_embedding.reshape(1,-1))[0][0]\n",
    "cosine_distance_rounded = round(cosine_distance.item(), 2)\n",
    "print(f\"Cosine distance between the two texts: {cosine_distance_rounded}\")\n",
    "print(type(cosine_distance))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-23T05:15:15.522052700Z",
     "start_time": "2023-06-23T05:15:15.512053600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "4b4fb936",
   "metadata": {},
   "source": [
    "# Задание 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af1adfb",
   "metadata": {},
   "source": [
    "Используя модель \"EleutherAI/gpt-neo-1.3B\" (huggingface), сгенерируйте продолжение следующего текста: \n",
    "\"Who knew that\".\n",
    "\n",
    "Используйте следующее параметры при генерации: минимальная длина продолжения - 20 токенов, максимальная длина продолжения - 200 токенов, отсутствие повторов длиной 3 токена, отсутствие семплирование (выбирается только самый вероятный токен).\n",
    "\n",
    "Вставьте сгенерированный текст в форму целиком (кавычки лучше не включать, но сработает и с ними)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6055b4eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# установите последние версии \n",
    "# !pip install transformers accelerate --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "681a6441",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T05:24:27.454434400Z",
     "start_time": "2023-06-23T05:19:16.788444200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading pytorch_model.bin:   0%|          | 0.00/5.31G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "433b32e7df6c44d79d94172cdefb4e7e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)olve/main/vocab.json: 0.00B [00:00, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3440c630e0df4958ac43f4dc1e3623c6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)olve/main/merges.txt: 0.00B [00:00, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c9ff07299be145bb89abd2ef9f0b62b7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7a628da9cd4944aa8e99a2272dc7f036"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)okenizer_config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c62c292354ef424a8945716a63b07213"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who knew that the world would be so lucky to have a woman like you?\n",
      "\n",
      "I’m not sure if I’ve ever been so happy to be in a relationship. I‘ve been in a few, but I”m not really sure what I“m supposed to do with them. I don”t know if I want to be with someone who is so much more than just a friend. I want someone who I can be myself with, who I feel comfortable with, and who I know I can trust. I know that I� “can” trust her, but it”s not the same as being able to trust her.\n",
      "\n",
      "It’s not that I don;t trust her; I just don’t know how to be around her. I feel like I„m not good enough for her. She”ll never know how much I love her, and I don “\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
    "\n",
    "model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "\n",
    "prompt = \"Who knew that\"\n",
    "input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "\n",
    "output = model.generate(\n",
    "    input_ids,\n",
    "    min_length=20,\n",
    "    max_length=200,\n",
    "    no_repeat_ngram_size=3,\n",
    "    do_sample=False\n",
    ")\n",
    "\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
