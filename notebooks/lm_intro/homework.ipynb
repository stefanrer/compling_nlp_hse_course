{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00fad453",
   "metadata": {},
   "source": [
    "# Домашнее задание № 4. Языковые модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d056af4",
   "metadata": {},
   "source": [
    "## Задание 1 (8 баллов)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f532a8",
   "metadata": {},
   "source": [
    "В семинаре для генерации мы использовали предположение маркова и считали, что слово зависит только от 1 предыдущего слова. Но ничто нам не мешает попробовать увеличить размер окна и учитывать два или даже три прошлых слова. Для них мы еще сможем собрать достаточно статистик и, логично предположить, что качество сгенерированного текста должно вырасти."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de743d1d",
   "metadata": {},
   "source": [
    "Попробуйте сделать языковую модель, которая будет учитывать два предыдущих слова при генерации текста.\n",
    "Сгенерируйте несколько текстов (3-5) и расчитайте перплексию получившейся модели. \n",
    "Можно использовать данные из семинара или любые другие (сопоставимые или большие по объему). Перплексию рассчитывайте на 10-50 отложенных предложениях (они не должны использоваться при сборе статистик).\n",
    "\n",
    "\n",
    "Подсказки:  \n",
    "    - нужно будет добавить еще один тэг <start>  \n",
    "    - еще одна матрица не нужна, можно по строкам хронить биграмы, а по колонкам униграммы  \n",
    "    - тексты должны быть очень похожи на нормальные (если у вас получается рандомная каша, вы что-то делаете не так)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from collections import Counter\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from scipy.sparse import lil_matrix\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T16:53:15.106282200Z",
     "start_time": "2023-06-09T16:53:15.100018400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "news = open('lenta.txt', encoding='UTF8').read()\n",
    "\n",
    "def normalize(text):\n",
    "    normalized_text = [word.text.strip(punctuation) for word \\\n",
    "                                                            in razdel_tokenize(text)]\n",
    "    normalized_text = [word.lower() for word in normalized_text if word and len(word) < 20 ]\n",
    "    return normalized_text\n",
    "\n",
    "def ngrammer(tokens, n=2):\n",
    "    ngrams = []\n",
    "    for i in range(0,len(tokens)-n+1):\n",
    "        ngrams.append(' '.join(tokens[i:i+n]))\n",
    "    return ngrams\n",
    "\n",
    "sentences_news = [['<start>', '<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(news[:5000000])]\n",
    "\n",
    "unigrams_news = Counter()\n",
    "bigrams_news = Counter()\n",
    "trigrams_news = Counter()\n",
    "\n",
    "for sentence in sentences_news:\n",
    "    unigrams_news.update(sentence)\n",
    "    bigrams_news.update(ngrammer(sentence))\n",
    "    trigrams_news.update(ngrammer(sentence, n=3))\n",
    "\n",
    "bigrams_news['<start> <start>'] = len(sentences_news)\n",
    "\n",
    "matrix_news = lil_matrix((len(bigrams_news), len(unigrams_news)))\n",
    "\n",
    "id2word_news = list(unigrams_news)\n",
    "word2id_news = {word:i for i, word in enumerate(id2word_news)}\n",
    "\n",
    "id2bigram_news = list(bigrams_news)\n",
    "bigram2id_news = {bigram:i for i, bigram in enumerate(id2bigram_news)}\n",
    "\n",
    "for ngram in trigrams_news:\n",
    "    word1, word2, word3 = ngram.split()\n",
    "    bigram = word1 + ' ' + word2\n",
    "    matrix_news[bigram2id_news[bigram], word2id_news[word3]] =  (trigrams_news[ngram] / bigrams_news[bigram])\n",
    "\n",
    "def generate(matrix, id2word, bigram2id, n=100, start='<start> <start>'):\n",
    "    text = []\n",
    "    current_bigram = start\n",
    "\n",
    "    for i in range(n):\n",
    "        chosen = np.random.choice(matrix.shape[1], p=matrix[bigram2id[current_bigram]].toarray()[0])\n",
    "        text.append(id2word[chosen])\n",
    "\n",
    "        if id2word[chosen] == '<end>':\n",
    "            current_bigram = '<start> <start>'\n",
    "        else:\n",
    "            current_bigram = current_bigram.split()[1] + ' ' + id2word[chosen]\n",
    "\n",
    "    return ' '.join(text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T16:53:20.588409500Z",
     "start_time": "2023-06-09T16:53:15.105290800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1 :\n",
      "основная причина распространения болезни отсутствие достаточных средств продолжать кампанию было бы странно если бы эти взрывы произошли то дома превратились бы в том числе 10 детей \n",
      " оформлением храма занимались творческие коллективы под руководством подполковника милиции абдулманапа мусаева \n",
      " структура договоренности уже согласована почти полностью контролируют старопромысловский район и организовали эвакуацию жителей соседних домов были срочно эвакуированы \n",
      " между тем соперник мэра иван стариков имеет достаточно теплые отношения прокуратура санкт-петербурга уже заявила журналистам риа новости игорь шабдурасулов о котором было заявлено на совместной пресс-конференции в воронеже охарактеризовал общую криминальную ситуацию в республике \n",
      " по окончании встречи прошедшей в пятницу прекращена\n",
      "\n",
      "Text 2 :\n",
      "россия каждый раз выражает свое принципиальное согласие баллотироваться на пост мэра столицы оставлено в силе вердикт суда первой инстанции признал незаконным и не может гарантировать населению безопасность на предстоящих парламентских выборов в йемене погибйеменец передало агентство риа новости со ссылкой на российское представительство компании не должны быть чище парламентской избирательной кампании в поддержку законно избранного премьер-министра \n",
      " в документе suppl doc автоматически рассылающемся вместе со спутником экспресс-а в среду 15 сентября около 3 тысяч компаний 20 стран бывшего восточного лагеря \n",
      " что же касается сотрудничества с украиной \n",
      " что касается предложения бориса березовского то как сообщил риа новости \n",
      " по\n",
      "\n",
      "Text 3 :\n",
      "оно начато европейской комиссией закон придающий контрактам заверенным электронными подписями тот же день депутаты избрали и о временном с 1 октября будущего года \n",
      " как сообщает федеральное агентство новостей исполняющий обязанности президента владимира путина \n",
      " кроме того есть показания некоторых членов фалуньгун привлекли к суду \n",
      " помощник президента россии владимира путина с представителями исполнительной власти региона приостановить финансирование краевой думы сергей грац выступавший доверенным лицом граждан держателей овгвз требующих выплат по облигациям на катастрофы nissan сократит 21 тысячу рабочих мест на двух серьезных нарушениях антимонопольного законодательства и условий намечены направления на остров пентекост входящий в состав комиссии также вошли представители\n",
      "\n",
      "Text 4 :\n",
      "пентагон тем временем на саммите в марте вице-президента луиса марии арганьи передает риа новости начальник отдела по борьбе с преступлениями договорился о сотрудничестве с офисом от россии \n",
      " минтранс рф проверил готовность компьютерных систем \n",
      " во вторник о выделении россии очередного кредитного транша по кредиту международного валютного фонда сообщает итар-тасс по поводу проблем связанных с выплатами пенсий является сложным но говорить о том что они ограничились отобранным автомобилем заявил ромарио репортерам пресс-секретарь президента алексей громов сообщает риа новости не станет заниматься политиканством \n",
      " чанчэн единственная корпорация в среду 17 ноября \n",
      " все что происходит в жизни страны и будет контролировать\n",
      "\n",
      "Text 5 :\n",
      "таким образом человек нельзя назвать политическими переговорами \n",
      " публикация швейцарского еженедельника о возбуждении дела против льва черного www chernoi с om \n",
      " американский генерал \n",
      " вешняков отметил что предстоит большая и сложная работа по обеспечению безопасности метрополитена по поводу займов ебрр что речь идет о привлечении вооруженных сил россии согласно гражданскому кодексу где говорится дословно следующее в совокупный доход за прошлый год доход в бюджет дополнительно 10 миллиардов долларов \n",
      " цель ее сорвать встречу в хельсинки завершился российско-финский семинар ес-россия усиление борьбы с терроризмом этой весной на территории поселка хомутово размещается воинская часть номер 33888 с крыши голубятни со стороны\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('Text', i+1, ':')\n",
    "    print(generate(matrix_news, id2word_news, bigram2id_news).replace('<end>', '\\n'))\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T17:00:51.332571Z",
     "start_time": "2023-06-09T17:00:51.100724300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 11388.14815381501\n"
     ]
    }
   ],
   "source": [
    "def perplexity(logp, N):\n",
    "    return np.exp((-1/N) * logp)\n",
    "\n",
    "\n",
    "def compute_joint_proba_trigram(text, matrix, word2id, bigram2id):\n",
    "    c_prob = 0\n",
    "    tokens = ['<start>', '<start>'] + normalize(text) + ['<end>']\n",
    "    for i in range(len(tokens)-2):\n",
    "        c_word1 = tokens[i]\n",
    "        c_word2 = tokens[i+1]\n",
    "        c_word3 = tokens[i+2]\n",
    "        bigram = c_word1 + ' ' + c_word2\n",
    "        if bigram in bigram2id and c_word3 in word2id:\n",
    "            p = matrix[bigram2id[bigram], word2id[c_word3]]\n",
    "            if p != 0:\n",
    "                c_prob += np.log(p)\n",
    "            else:\n",
    "                c_prob += np.log(1e-6)\n",
    "        else:\n",
    "            c_prob += np.log(1e-6)\n",
    "    return c_prob, len(tokens)\n",
    "\n",
    "ps = []\n",
    "for sent in sent_tokenize(news[5000000:5000050]):\n",
    "    t_prob, N = compute_joint_proba_trigram(sent, matrix_news, word2id_news, bigram2id_news)\n",
    "    if not N:\n",
    "        continue\n",
    "    ps.append(perplexity(t_prob, N))\n",
    "print('Perplexity:', np.mean(ps))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T17:12:53.926149800Z",
     "start_time": "2023-06-09T17:12:53.920633Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "8e0a8dd5",
   "metadata": {},
   "source": [
    "## Задание № 2* (2 балла). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b36c44b",
   "metadata": {},
   "source": [
    "Прочитайте главу про языковое моделирование в книге Журафски и Мартина - https://web.stanford.edu/~jurafsky/slp3/3.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9b1bd8",
   "metadata": {},
   "source": [
    "Развернуто (в пределах 1000 знаков) ответьте на вопросы (по-русски):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2cf844",
   "metadata": {},
   "source": [
    "1. Что можно делать с проблемой несловарных слов? В семинаре мы просто использовали какое-то маленькое значение вероятности, а какие есть другие способы?"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Проблема несловарных слов возникает, когда в тестовых данных встречаются слова, которых нет в обучающих данных. Один из способов решения этой проблемы - использование закрытой системы словарей, где тестовые данные могут содержать только слова из\n",
    "известного словаря. Однако в большинстве реальных ситуаций мы имеем дело с несловарными словами. Один из способов создания открытой системы словарей - моделирование потенциальных неизвестных слов в тестовых данных путем добавления псевдо-слова\n",
    "<UNK>.\n",
    "\n",
    "Существует два распространенных способа обучения вероятностей неизвестного слова <UNK>. Первый - это превращение проблемы обратно в закрытую систему словарей путем выбора фиксированного словаря заранее. Второй альтернативой, когда у нас нет заранее\n",
    "определенного словаря, является создание такого словаря неявно, заменяя слова в обучающих данных на <UNK> на основе их частоты.\n",
    "\n",
    "Точный выбор <UNK> влияет на метрики, такие как перплексия. Языковая модель может достичь низкой перплексии, выбрав маленький словарь и назначив неизвестному слову высокую вероятность. Таким образом, перплексии могут быть сравнены только между языковыми\n",
    "моделями с одинаковыми словарями."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "d1d1c152",
   "metadata": {},
   "source": [
    "2. Что такое сглаживание (smoothing)?"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    " Чтобы языковая модель не присваивала нулевую вероятность невиданным событиям(слова, которые есть в словаре, но встречаются в тестовых данных в невиданном контексте. Например, они появляются после слова, после которого они никогда не появлялись в\n",
    " обучающих данных), мы должны отнять немного вероятностной массы у более частых событий и отдать ее событиям, которые мы никогда не видели. Эта модификация называется сглаживанием или\n",
    " уценкой.\n",
    " Есть различные способы сглаживания: сглаживание Лапласа (add-one), сглаживание add-k, глупый откат (stupid backoff) и сглаживание Кнезера-Нея."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
